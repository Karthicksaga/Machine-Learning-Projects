{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3sNKZq4XrXQh"
   },
   "source": [
    "# <font color='red'><b>Bootstrap assignment</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RAHap1Z3FZC-"
   },
   "source": [
    "<b>There will be some functions that start with the word \"grader\" ex: grader_sampples(), grader_30().. etc, you should not change those function definition.\n",
    "\n",
    "Every Grader function has to return True.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cuxBq_bvrwh2"
   },
   "source": [
    "<font color='blue'> <b>Importing packages</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m6ag91ijrQOs"
   },
   "outputs": [],
   "source": [
    "import numpy as np # importing numpy for numerical computation\n",
    "from sklearn.datasets import load_boston # here we are using sklearn's boston dataset\n",
    "from sklearn.metrics import mean_squared_error # importing mean_squared_error metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CcHOsONTt1K_"
   },
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "x=boston.data #independent variables\n",
    "y=boston.target #target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pc1htEFYuLRj",
    "outputId": "f5b60712-98b3-4cdc-b629-3546c1e3859c",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "kQle3T_wuOa3",
    "outputId": "521c7bdd-5316-48d5-c534-b61d170d2c28",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, 0.0000e+00, 5.3800e-01,\n",
       "        6.5750e+00, 6.5200e+01, 4.0900e+00, 1.0000e+00, 2.9600e+02,\n",
       "        1.5300e+01, 3.9690e+02, 4.9800e+00],\n",
       "       [2.7310e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
       "        6.4210e+00, 7.8900e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
       "        1.7800e+01, 3.9690e+02, 9.1400e+00],\n",
       "       [2.7290e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
       "        7.1850e+00, 6.1100e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
       "        1.7800e+01, 3.9283e+02, 4.0300e+00],\n",
       "       [3.2370e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
       "        6.9980e+00, 4.5800e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
       "        1.8700e+01, 3.9463e+02, 2.9400e+00],\n",
       "       [6.9050e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
       "        7.1470e+00, 5.4200e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
       "        1.8700e+01, 3.9690e+02, 5.3300e+00]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AEa_HqRZloH4"
   },
   "source": [
    "## <font color='red'><b>Task 1</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YQ5q8IxHNRk3"
   },
   "source": [
    "<font color='red'> <b>Step - 1</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GJCFCaOzl7Mr"
   },
   "source": [
    "*  <font color='blue'><b>Creating samples</b></font><br>\n",
    "    <b> Randomly create 30 samples from the whole boston data points</b>\n",
    "    *  Creating each sample: Consider any random 303(60% of 506) data points from whole data set and then replicate any 203 points from the sampled points\n",
    "    \n",
    "     For better understanding of this procedure lets check this examples, assume we have 10 data points [1,2,3,4,5,6,7,8,9,10], first we take 6 data points randomly , consider we have selected [4, 5, 7, 8, 9, 3] now we will replicate 4 points from [4, 5, 7, 8, 9, 3], consder they are [5, 8, 3,7] so our final sample will be [4, 5, 7, 8, 9, 3, 5, 8, 3,7]\n",
    "* <font color='blue'><b> Create 30 samples </b></font>\n",
    "    *  Note that as a part of the Bagging when you are taking the random samples <b>make sure each of the sample will have different set of columns</b><br>\n",
    "Ex: Assume we have 10 columns[1 ,2 ,3 ,4 ,5 ,6 ,7 ,8 ,9 ,10] for the first sample we will select [3, 4, 5, 9, 1, 2] and for the second sample  [7, 9, 1, 4, 5, 6, 2] and so on...\n",
    "Make sure each sample will have atleast 3 feautres/columns/attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zUqFEBSvNjCa"
   },
   "source": [
    "<font color='red'><b>Step - 2 </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uqi9AhCYNq3Z"
   },
   "source": [
    "<font color='blue'><b>Building High Variance Models on each of the sample and finding train MSE value</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lLBnZHXOFln"
   },
   "source": [
    "*  Build a regression trees on each of 30 samples.\n",
    "*  Computed the predicted values of each data point(506 data points) in your corpus.\n",
    "*  Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{30}\\sum_{k=1}^{30}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$\n",
    "*  Now calculate the $MSE =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kls23JLnSN23"
   },
   "source": [
    "<font color='red'> <b>Step - 3 </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rz2GchkGSWnh"
   },
   "source": [
    "*  <font color='blue'><b>Calculating the OOB score </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DGHkVV2kSibm"
   },
   "source": [
    "*  Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{k}\\sum_{\\text{k= model which was buit on samples not included } x^{i}}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$.\n",
    "*  Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RK860ocxTyoz"
   },
   "source": [
    "# <font color='red'><b>Task 2</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1dme-N6TUCrY"
   },
   "source": [
    "*  <font color='blue'><b>Computing CI of OOB Score and Train MSE</b></font>\n",
    "  *   Repeat Task 1 for 35 times, and for each iteration store the Train MSE and OOB score </li>\n",
    "<li> After this we will have 35 Train MSE values and 35 OOB scores </li>\n",
    "<li> using these 35 values (assume like a sample) find the confidence intravels of MSE and OOB Score </li>\n",
    "<li> you need to report CI of MSE and CI of OOB Score </li>\n",
    "<li> Note: Refer the Central_Limit_theorem.ipynb to check how to find the confidence intravel</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O6UcH1x9Uwrj"
   },
   "source": [
    "# <font color='red'><b>Task 3</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bOC_AgsLU7OH"
   },
   "source": [
    "*  <font color='blue'><b>Given a single query point predict the price of house.</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HYs5jSFdVILe"
   },
   "source": [
    "Consider xq= [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60] \n",
    "Predict the house price for this point as mentioned in the step 2 of Task 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_6gxZEsFWm-8"
   },
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V2fHTdS_zpgG"
   },
   "source": [
    "# <font color='blue'> <b>Task - 1</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e0yGBuryOwHz"
   },
   "source": [
    "<font color='blue'><b>Step - 1</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lJXX8vf3z073"
   },
   "source": [
    "*  <font color='blue'> <b>Creating samples</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CSVaWG1F4uCZ"
   },
   "source": [
    "<font color='Orange'><b>Algorithm</b></font>\n",
    "\n",
    "![alt text](https://i.imgur.com/BTVYXQ1.jpg/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f_oWoN97BhDY"
   },
   "source": [
    "*  <font color='blue'><b> Write code for generating samples</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ph_6D2SDzz7F"
   },
   "outputs": [],
   "source": [
    "\n",
    "def generating_samples(input_data, target_data):\n",
    "\n",
    "    '''In this function, we will write code for generating 30 samples '''\n",
    "    # you can use random.choice to generate random indices without replacement\n",
    "    # Please have a look at this link https://docs.scipy.org/doc/numpy-1.16.0/reference/generated/numpy.random.choice.html for more details\n",
    "    # Please follow above pseudo code for generating samples \n",
    "    \n",
    "    #input_data represents the independent_feature and target_data represents the output feature/ dependent_feature\n",
    "    \n",
    "    #select the row indices for the input data randomly without replacement\n",
    "    select_row_indices = np.random.choice(input_data.shape[0],303,replace = False)\n",
    "    #print(select_row_indices)\n",
    "    #repeat the selected indices to to construct the remaing datapoint\n",
    "    repeating_rows = np.random.randint(0,len(select_row_indices),203)\n",
    "    \n",
    "    #select the column incices without replacement #np.random.randint generate the random number between 3 to 13\n",
    "    select_column_indices = np.random.choice(input_data.shape[1],np.random.randint(3,13,1)[0],replace = False)\n",
    "    \n",
    "    #https://github.com/numpy/numpy/issues/13255 broadcasting error for multi dimentional mask\n",
    "    sample_data = input_data[select_row_indices][:,select_column_indices]\n",
    "    \n",
    "    #slicing the output feature rows\n",
    "    target_sample_data = target_data[select_row_indices]\n",
    "    \n",
    "    \n",
    "    #Replicating the data \n",
    "    \n",
    "    #https://www.geeksforgeeks.org/numpy-vstack-in-python/\n",
    "    replicated_sample_data = sample_data[repeating_rows]\n",
    "    #print(replicated_sample_data.shape)\n",
    "    \n",
    "    target_of_replicated_sample_data = target_data[repeating_rows]\n",
    "    \n",
    "    #merge the data sample \n",
    "    final_sample_data = np.vstack((sample_data,replicated_sample_data))\n",
    "    \n",
    "    #merge the output feature\n",
    "    final_target_data = np.vstack((target_sample_data.reshape(-1,1),target_of_replicated_sample_data.reshape(-1,1)))\n",
    "    \n",
    "    return final_sample_data,final_target_data,select_row_indices,select_column_indices\n",
    "    # return sampled_input_data , sampled_target_data,selected_rows,selected_columns\n",
    "    #note please return as lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MivEQFlm7iOg"
   },
   "source": [
    "<font color='cyan'> <b> Grader function - 1 </b> </fongt>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AVvuhNzm7uld"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_samples(a,b,c,d):\n",
    "    length = (len(a)==506  and len(b)==506)\n",
    "    sampled = (len(a)-len(set([str(i) for i in a]))==203)\n",
    "    rows_length = (len(c)==303)\n",
    "    column_length= (len(d)>=3)\n",
    "    assert(length and sampled and rows_length and column_length)\n",
    "    return True\n",
    "a,b,c,d = generating_samples(x, y)\n",
    "grader_samples(a,b,c,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b4LSsmn4Jn2_"
   },
   "source": [
    "*  <font color='blue'> <b>Create 30 samples </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ec7MN6sL2BZ"
   },
   "source": [
    "![alt text](https://i.imgur.com/p8eZaWL.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XXlKWjCcBvTk"
   },
   "outputs": [],
   "source": [
    "# Use generating_samples function to create 30 samples \n",
    "# store these created samples in a list\n",
    "list_input_data =[]\n",
    "list_output_data =[]\n",
    "list_selected_row= []\n",
    "list_selected_columns=[]\n",
    "\n",
    "for i in range(0,30):\n",
    "    a,b,c,d = generating_samples(x,y)\n",
    "    list_input_data.append(a)\n",
    "    list_output_data.append(b)\n",
    "    list_selected_row.append(c)\n",
    "    list_selected_columns.append(d)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MXUz9VFiMQkh"
   },
   "source": [
    "<font color='cyan'> <b>Grader function - 2 </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hCvIq8NuMWOC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_30(a):\n",
    "    assert(len(a)==30 and len(a[0])==506)\n",
    "    return True\n",
    "grader_30(list_input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Pv-mkZkO6dh"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "whaHCPB0O8qF"
   },
   "source": [
    "<font color='red'><b>Step - 2 </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XBy4zXSWPtU8"
   },
   "source": [
    "<font color='orange'><b>Flowchart for building tree</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5xvH06HPQBdP"
   },
   "source": [
    "![alt text](https://i.imgur.com/pcXfSmp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WRwPO_uHQjul"
   },
   "source": [
    "*  <font color='blue'><b> Write code for building regression trees</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YWQp6tRwMthq",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def regression_tree(list_input_data,list_output_data):\n",
    "    \n",
    "    model_list = []\n",
    "    \n",
    "    for idx in range(len(list_input_data)):\n",
    "        #print(x_train.shape,y_train.shape)\n",
    "        tree = DecisionTreeRegressor(max_depth = None)\n",
    "        \n",
    "        model = tree.fit(list_input_data[idx],list_output_data[idx])\n",
    "        model_list.append(model)\n",
    "    return model_list\n",
    "list_model = regression_tree(list_input_data,list_output_data)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "21j8BKfAQ1U8"
   },
   "source": [
    "<font color='orange'><b>Flowchart for calculating MSE </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Q0mTBD2RBx_"
   },
   "source": [
    "![alt text](https://i.imgur.com/sPEE618.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6e-UamlHRjPy"
   },
   "source": [
    "After getting predicted_y for each data point, we can use sklearns mean_squared_error to calculate the MSE between predicted_y and actual_y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TnIMT7_oR312"
   },
   "source": [
    "*  <font color='blue'><b> Write code for calculating MSE</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qWhcvMRWRA9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the predicted Models :(30, 506)\n"
     ]
    }
   ],
   "source": [
    "def model_performance(input_data,list_model,list_selected_column):\n",
    "    \n",
    "    y_predict_list = []\n",
    "    \n",
    "    #prediction for the original_data,#Iterate Each model with selected column\n",
    "    for model,sampled_column in zip(list_model,list_selected_column):\n",
    "           \n",
    "        #print(len(sampled_column))\n",
    "        y_pred = model.predict(input_data[:,sampled_column])\n",
    "        \n",
    "        #append the each model prediction\n",
    "        y_predict_list.append(y_pred)\n",
    "    \n",
    "    return np.array(y_predict_list)\n",
    "\n",
    "#Pediction for all the 30 model\n",
    "y_predict_list = model_performance(x,list_model,list_selected_columns)\n",
    "\n",
    "print(\"Shape of the predicted Models :{0}\".format(y_predict_list.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the aggregated Model (506, 1)\n"
     ]
    }
   ],
   "source": [
    "#print(type(y_predict_list))\n",
    "\n",
    "#Compute the Median of the 30 model prediction\n",
    "#Aggregate the all model into single model to predict the o/p \n",
    "#In regression We use aggregation as Median/mean to dececide the predicted class label\n",
    "mean_of_y_pred = np.mean(y_predict_list.T,axis = 1)\n",
    "print(\"Shape of the aggregated Model {0}\".format(mean_of_y_pred.reshape(-1,1).shape))\n",
    "#print(y.reshape(-1,1).shape)\n",
    "#compute the performance of the model mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean square error : 12.778534811209928\n"
     ]
    }
   ],
   "source": [
    "def mean_square_error(actual_value,predicted_value):\n",
    "    mse =  0.0\n",
    "    #check  the lenght length both the value\n",
    "    if len(actual_value) == len(predicted_value):\n",
    "        \n",
    "        for i in range(len(actual_value)):\n",
    "            \n",
    "            mse += (actual_value[i] - predicted_value[i]) ** 2\n",
    "        \n",
    "        \n",
    "    mse  = mse /  len(actual_value)\n",
    "    \n",
    "    return mse\n",
    "    \n",
    "mean_squared_error  = mean_square_error(y,mean_of_y_pred)\n",
    "#print('Mean square error : {0}'.format(mean_squared_error(y.reshape(-1,1),median_of_y_pred.reshape(-1,1))))\n",
    "print('Mean square error : {0}'.format(mean_squared_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RuclPDMnSz8F"
   },
   "source": [
    "<font color='blue'><b>Step - 3 </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ESb9FSIDTM5V"
   },
   "source": [
    "<font color='orange'><b>Flowchart for calculating OOB score</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HB-d6NMETbd9"
   },
   "source": [
    "![alt text](https://i.imgur.com/95S5Mtm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WW3GOcFzTqbt"
   },
   "source": [
    "Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zBqcS03pUYSZ"
   },
   "source": [
    "*  <font color='blue'><b> Write code for calculating OOB score </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fog_6DNdS-h_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the y_prediction_list: (506,)\n",
      "OOB Score : 22.70470218763723\n"
     ]
    }
   ],
   "source": [
    "#https://towardsdatascience.com/what-is-out-of-bag-oob-score-in-random-forest-a7fa23d710\n",
    "def predict_data_on_oob(x,y,list_of_model,selecting_row_index_list,selecting_column_list):\n",
    "    \n",
    "    oob_predicted_score = []\n",
    "    \n",
    "    y_predict_list = []\n",
    "\n",
    "    \n",
    "    # iterate all the data samples\n",
    "    for idx_row in range(x.shape[0]):\n",
    "      \n",
    "        predict_oob_data_model = []\n",
    "        \n",
    "        predicted_unseen_query_point_list = []\n",
    "        \n",
    "        y_prediction_models = []\n",
    "            \n",
    "        subset_data_model_sampling_column = []\n",
    "        \n",
    "        #select the model have the index is not present in the model indices\n",
    "        for idx_model in range(len(list_of_model)):\n",
    "            \n",
    "            if idx_row not in selecting_row_index_list[idx_model]:\n",
    "                \n",
    "                #example the corresponding row is not present in the given  subset of the sample and  select the model \n",
    "                predict_oob_data_model.append(list_of_model[idx_model])\n",
    "                \n",
    "                #get the sampling columns corresponding model and convert array to list\n",
    "                subset_data_model_sampling_column.append(selecting_column_list[idx_model].tolist())\n",
    "                \n",
    "                #print(subset_data_model_sampling_column)\n",
    "        \n",
    "        #Iterate selected model which is the data is present in the sample    \n",
    "        for idx in range(len(predict_oob_data_model)):\n",
    "            \n",
    "            #query\n",
    "            unseen_data = x[idx_row]\n",
    "            \n",
    "            #sampling the columns -->> corresponding to the model\n",
    "            unseen_data = unseen_data[subset_data_model_sampling_column[idx]]\n",
    "        \n",
    "            #predict the given query not seen in the training data\n",
    "            #print(type(predict_oob_query))\n",
    "            #print(predict_oob_query)\n",
    "        \n",
    "            #predict the  new query point not present in the samples\n",
    "            y_predict_unseen_data = predict_oob_data_model[idx].predict(np.array(unseen_data).reshape(1,-1))\n",
    "            \n",
    "            \n",
    "            #predict_oob_data_model.append(predict_oob_query)\n",
    "            \n",
    "            predicted_unseen_query_point_list.append(y_predict_unseen_data)\n",
    "            \n",
    "        \n",
    "        #Predicted house price of  𝑖𝑡ℎ  data point  take the average of the query point\n",
    "        mean_of_the_datapoint = np.median(predicted_unseen_query_point_list)\n",
    "        #print(predicted_unseen_query_point_list.shape)\n",
    "        y_predict_list.append(mean_of_the_datapoint)\n",
    "\n",
    "    return np.array(y_predict_list)\n",
    "\n",
    "\n",
    "def calculate_oob_score(actual_value,predicted_value):\n",
    "    #out of bag _score \n",
    "    oobScore =  0.0\n",
    "    if len(actual_value) == len(predicted_value):\n",
    "        \n",
    "        for i in range(len(actual_value)):\n",
    "            size = actual_value[i] - predicted_value[i]\n",
    "            oobScore += (actual_value[i] - predicted_value[i]) ** 2\n",
    "        \n",
    "        \n",
    "    oobScore  = oobScore /  len(actual_value)\n",
    "    \n",
    "    return oobScore\n",
    "\n",
    "\n",
    "y_prediction_list = predict_data_on_oob(x,y,list_model,list_selected_row,list_selected_columns)\n",
    "\n",
    "oobScore = calculate_oob_score(y,y_prediction_list)\n",
    "\n",
    "print(\"Shape of the y_prediction_list: {0}\".format(y_prediction_list.shape))\n",
    "\n",
    "print(\"OOB Score : {0}\".format(oobScore))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sbuiwX3OUjUI"
   },
   "source": [
    "# <font color='blue'><b>Task 2</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing CI of OOB Score and Train MSE\n",
    "\n",
    "Repeat Task 1 for 35 times, and for each iteration store the Train MSE and OOB score\n",
    "\n",
    "After this we will have 35 Train MSE values and 35 OOB scores\n",
    "\n",
    "using these 35 values (assume like a sample) find the confidence intravels of MSE and OOB Score\n",
    "you need to report CI of MSE and CI of OOB Score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute CI of OOBSCore and Train MSE\n",
    "\n",
    "#Genrating 35 Samples to compute the confindence Intereval\n",
    "\n",
    "def generate_sample_to_compute_confidence_interval(x,y):\n",
    "\n",
    "\n",
    "    mean_squared_error_sample_list = []\n",
    "\n",
    "    oob_Score_sample_list = []\n",
    "\n",
    "    for i in range(0,35):\n",
    "\n",
    "        list_input_data =[]\n",
    "        list_output_data =[]\n",
    "        list_selected_row= []\n",
    "        list_selected_columns=[]\n",
    "\n",
    "\n",
    "        for i in range(0,30):\n",
    "            a,b,c,d = generating_samples(x,y)\n",
    "            list_input_data.append(a)\n",
    "            list_output_data.append(b)\n",
    "            list_selected_row.append(c)\n",
    "            list_selected_columns.append(d)\n",
    "\n",
    "        #generate k regression trees\n",
    "        list_model = regression_tree(list_input_data,list_output_data) \n",
    "\n",
    "        #predict the data\n",
    "        y_predict_list = model_performance(x,list_model,list_selected_columns)\n",
    "\n",
    "        mean_of_y_pred = np.mean(y_predict_list.T,axis = 1)\n",
    "        #compute the Mean squaredError for the predicted model\n",
    "        mean_squared_error  = mean_square_error(y,mean_of_y_pred)\n",
    "\n",
    "        #predict the unseen data in training time\n",
    "        y_prediction_list = predict_data_on_oob(x,y,list_model,list_selected_row,list_selected_columns)\n",
    "\n",
    "        #compute oob_score for the predicted model\n",
    "        oobScore = calculate_oob_score(y,y_prediction_list)\n",
    "\n",
    "        #add the mean square error in the list\n",
    "        mean_squared_error_sample_list.append(mean_squared_error)\n",
    "\n",
    "        \n",
    "        oob_Score_sample_list.append(oobScore)\n",
    "        \n",
    "    return (mean_squared_error_sample_list,oob_Score_sample_list)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error_sample_list, oob_Score_sample_list= generate_sample_to_compute_confidence_interval(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Interval for Mean Squared Error : [12.207, 12.734]\n",
      "Confidence Interval for OOB Score : [23.305, 24.696]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "n = 35\n",
    "#step 1 : caculate its mean  of sample\n",
    "mean_squared_error_sample_list = np.array(mean_squared_error_sample_list)\n",
    " \n",
    "oob_Score_sample_list =  np.array(oob_Score_sample_list)\n",
    "sample_mean_of_mse = np.mean(mean_squared_error_sample_list)\n",
    "\n",
    "sample_mean_of_oob = np.mean(oob_Score_sample_list)\n",
    "\n",
    "\n",
    "#Step 2. compute the std deviation of the sample std \n",
    "\n",
    "std_mse = np.std(mean_squared_error_sample_list)\n",
    "\n",
    "std_oob = np.std(oob_Score_sample_list)\n",
    "\n",
    "#std_error = sample_std / sqroot(n)\n",
    "std_error_mse  = std_mse / math.sqrt(n)\n",
    "\n",
    "std_error_oob = std_oob / math.sqrt(n)\n",
    "\n",
    "#print(std_mse)\n",
    "\n",
    "print(\"Confidence Interval for Mean Squared Error : {0}\".format([np.round(sample_mean_of_mse - (2 * std_error_mse),3), \\\n",
    "                                                                 np.round(sample_mean_of_mse + (2 *std_error_mse),3)]))\n",
    "\n",
    "print(\"Confidence Interval for OOB Score : {0}\".format([np.round(sample_mean_of_oob - (2 *std_error_oob),3), \\\n",
    "                                                                 np.round(sample_mean_of_oob + (2 *std_error_oob),3)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.we can say 95% confidence to perform error(MES) in the range between [12.207, 12.734]  population datasat with 35 samples MSE \n",
    "\n",
    "2.we can say 95% confidence to OOB Score in the range between  [23.305, 24.696] to unseen data based on the sample mean and std population datasat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jKTnJdiBVS_e"
   },
   "source": [
    "# <font color='blue'><b>Task 3</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eXxrvZqHV1Fr"
   },
   "source": [
    "<font color='orange'><b>Flowchart for Task 3</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NyjwEJ62V6a6"
   },
   "source": [
    "<b>Hint: </b> We created 30 models by using 30 samples in TASK-1. Here, we need send query point \"xq\"  to 30 models and perform the regression on the output generated by 30 models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0emSwLL7VurD"
   },
   "source": [
    "![alt text](https://i.imgur.com/Y5cNhQk.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "29hjwKlWWDfo"
   },
   "source": [
    "*  <font color='blue'><b> Write code for TASK 3 </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i_pUlSD-VYD1"
   },
   "outputs": [],
   "source": [
    "#Predict the house price - unseen data \n",
    "def predict_new_data(x_q,model_list,list_selected_columns):\n",
    "    \n",
    "    y_predict_list = []\n",
    "    \n",
    "    for i in range(len(model_list)):\n",
    "        \n",
    "        Y_predict = model_list[i].predict(x_q[list_selected_columns[i]].reshape(1,-1))\n",
    "        \n",
    "        y_predict_list.append(Y_predict)\n",
    "        \n",
    "    return np.mean(np.array(y_predict_list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value of House Price : 23.243333333333336\n"
     ]
    }
   ],
   "source": [
    "x_q = np.array([0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60])\n",
    "predicted_price = predict_new_data(x_q,list_model,list_selected_columns)\n",
    "\n",
    "print(\"Predicted value of House Price : {0}\".format(predicted_price))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Bootstrap_assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
