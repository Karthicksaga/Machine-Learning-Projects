{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8ArWK463kbhL",
    "outputId": "ad250ffe-29ed-4dc9-bf30-fe91ab10656c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.4.2.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5mldzJdakbhS"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('task_b.csv')\n",
    "data=data.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rsCrC2wckbhV",
    "outputId": "fff03fba-880e-4875-9bba-f05797f08d1d",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-195.871045</td>\n",
       "      <td>-14843.084171</td>\n",
       "      <td>5.532140</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1217.183964</td>\n",
       "      <td>-4068.124621</td>\n",
       "      <td>4.416082</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.138451</td>\n",
       "      <td>4413.412028</td>\n",
       "      <td>0.425317</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>363.824242</td>\n",
       "      <td>15474.760647</td>\n",
       "      <td>1.094119</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-768.812047</td>\n",
       "      <td>-7963.932192</td>\n",
       "      <td>1.870536</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            f1            f2        f3    y\n",
       "0  -195.871045 -14843.084171  5.532140  1.0\n",
       "1 -1217.183964  -4068.124621  4.416082  1.0\n",
       "2     9.138451   4413.412028  0.425317  0.0\n",
       "3   363.824242  15474.760647  1.094119  0.0\n",
       "4  -768.812047  -7963.932192  1.870536  0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FI18joJ_kbhZ",
    "outputId": "22e420e9-4295-4307-a60f-1a528d07c81d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1    0.067172\n",
       "f2   -0.017944\n",
       "f3    0.839060\n",
       "y     1.000000\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u40oCVMikbhc",
    "outputId": "db6dce7e-7469-4aa5-8af3-1c08cd0f0081",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1      488.195035\n",
       "f2    10403.417325\n",
       "f3        2.926662\n",
       "y         0.501255\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yQIbNaHskbhe",
    "outputId": "f2298482-b1d5-47e0-f15c-31f4a753a9ac",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 3)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "X=data[['f1','f2','f3']].values\n",
    "Y=data['y'].values\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aUxp9-qEkbhh"
   },
   "source": [
    "# What if our features are with different variance \n",
    "\n",
    "<pre>\n",
    "* <b>As part of this task you will observe how linear models work in case of data having feautres with different variance</b>\n",
    "* <b>from the output of the above cells you can observe that var(F2)>>var(F1)>>Var(F3)</b>\n",
    "\n",
    "> <b>Task1</b>:\n",
    "    1. Apply Logistic regression(SGDClassifier with logloss) on 'data' and check the feature importance\n",
    "    2. Apply SVM(SGDClassifier with hinge) on 'data' and check the feature importance\n",
    "\n",
    "> <b>Task2</b>:\n",
    "    1. Apply Logistic regression(SGDClassifier with logloss) on 'data' after standardization \n",
    "       i.e standardization(data, column wise): (column-mean(column))/std(column) and check the feature importance\n",
    "    2. Apply SVM(SGDClassifier with hinge) on 'data' after standardization \n",
    "       i.e standardization(data, column wise): (column-mean(column))/std(column) and check the feature importance\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TbMnsrxakbhi"
   },
   "source": [
    "<h3><font color='blue'> Make sure you write the observations for each task, why a particular feautre got more importance than others</font></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Build a Model Without Feature Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 -coefficient : 1953.2570698207414\n",
      "f1 - absolute weight : 1953.2570698207414\n",
      "==================================================\n",
      "f2 -coefficient : -16467.82281633211\n",
      "f2 - absolute weight : 16467.82281633211\n",
      "==================================================\n",
      "f3 -coefficient : 10594.926936428314\n",
      "f3 - absolute weight : 10594.926936428314\n",
      "==================================================\n",
      "Score :0.525\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with SGD Classifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "logistic = SGDClassifier(loss ='log')\n",
    "logistic.fit(X,Y)\n",
    "#coeff\n",
    "coeff = logistic.coef_\n",
    "features = data.columns\n",
    "for feature,coef in zip(features[:-1],coeff[0]):\n",
    "    print(\"{0} -coefficient : {1}\".format(feature,coef))\n",
    "    print('{0} - absolute weight : {1}'.format(feature,abs(coef)) )\n",
    "    print(\"=\"*50)\n",
    "print('Score :{}'.format(logistic.score(X,Y)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 -coefficient : 10260.587068136601\n",
      "f1 - absolute weight : 10260.587068136601\n",
      "==================================================\n",
      "f2 -coefficient : -2091.97196298414\n",
      "f2 - absolute weight : 2091.97196298414\n",
      "==================================================\n",
      "f3 -coefficient : 11098.507935917825\n",
      "f3 - absolute weight : 11098.507935917825\n",
      "==================================================\n",
      "Score :0.545\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with SGD Classifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "svm = SGDClassifier(loss ='hinge')\n",
    "svm.fit(X,Y)\n",
    "#coeff\n",
    "coeff = svm.coef_\n",
    "features = data.columns\n",
    "for feature,coef in zip(features[:-1],coeff[0]):\n",
    "    print(\"{0} -coefficient : {1}\".format(feature,coef))\n",
    "    print('{0} - absolute weight : {1}'.format(feature,abs(coef)) )\n",
    "    print(\"=\"*50)\n",
    "print('Score :{}'.format(svm.score(X,Y)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Important is useful to Decide the Class Label  \n",
    "\n",
    "Weight tells which Feature Important for predicting the class label\n",
    "In this Situation Feature f1 and f3 is weight Positive Weights,F3 Feature is Highest Positive Weight, so Feature F3 is More Important for deciding the class label as positive,f1 is less important comparing to f3\n",
    "\n",
    "The feature f2 is Negative is used to decide the class label negative,because f2 weight is negative\n",
    "\n",
    "AS We Observe the Training Performance for Models Logistic Regession and SVM, The Models Not Perform Good in Training time.as Considerd as Average Because of High Varience of Features has high Varience. if the Varience is High distance from the points is increased Lot of Miss classification happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 -coefficient : -1.803327383728873\n",
      "f1 - absolute weight : 1.803327383728873\n",
      "==================================================\n",
      "f2 -coefficient : 3.286491308755802\n",
      "f2 - absolute weight : 3.286491308755802\n",
      "==================================================\n",
      "f3 -coefficient : 11.127307064509534\n",
      "f3 - absolute weight : 11.127307064509534\n",
      "==================================================\n",
      "Score :0.91\n"
     ]
    }
   ],
   "source": [
    "#Standardized_data\n",
    "X_std = StandardScaler().fit_transform(X)\n",
    "logistic = SGDClassifier(loss ='log')\n",
    "logistic.fit(X_std,Y)\n",
    "#coeff\n",
    "coeff = logistic.coef_\n",
    "features = data.columns\n",
    "for feature,coef in zip(features[:-1],coeff[0]):\n",
    "    print(\"{0} -coefficient : {1}\".format(feature,coef))\n",
    "    print('{0} - absolute weight : {1}'.format(feature,abs(coef)) )\n",
    "    print(\"=\"*50)\n",
    "print('Score :{}'.format(logistic.score(X_std,Y)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 -coefficient : -7.56952434037253\n",
      "f1 - absolute weight : 7.56952434037253\n",
      "==================================================\n",
      "f2 -coefficient : -0.9831145132336695\n",
      "f2 - absolute weight : 0.9831145132336695\n",
      "==================================================\n",
      "f3 -coefficient : 21.67907853796233\n",
      "f3 - absolute weight : 21.67907853796233\n",
      "==================================================\n",
      "Score :0.905\n"
     ]
    }
   ],
   "source": [
    "# Standardizing Svm\n",
    "\n",
    "svm = SGDClassifier(loss ='hinge')\n",
    "svm.fit(X_std,Y)\n",
    "#coeff\n",
    "coeff = svm.coef_\n",
    "features = data.columns\n",
    "for feature,coef in zip(features[:-1],coeff[0]):\n",
    "    print(\"{0} -coefficient : {1}\".format(feature,coef))\n",
    "    print('{0} - absolute weight : {1}'.format(feature,abs(coef)) )\n",
    "    print(\"=\"*50)\n",
    "print('Score :{}'.format(svm.score(X_std,Y)))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Standardizing the Features weights is completely changed,Because all the Fetures distribution in the range -1 to 1\n",
    "When We apply the standardized features both the model Perform good we got Better Accuracy, So High Varience is Affect the model Performance\n",
    "if the varience is high model is too underfit\n",
    "\n",
    "In Logitic Regression  f2 and f3 is weight is large positive so impact to the model lot of large predicting \n",
    "poitive,feature f1 is impact to predict the class label as negative\n",
    "\n",
    "SVM f1 and f2 is weight is large positive so impact to the model lot of large predicting \n",
    "poitive,feature f1 is impact to predict the class label as negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Feature Scaling is Important Before Build the Model,it affect the Model Performance,we saw Logistic regression and Svm Not perform well in training well\n",
    "\n",
    "2.Model Performance and Feature Importance Changed After Standardization\n",
    "\n",
    "3.feature has More Weight is considered as important features"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "8B_LR_SVM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
